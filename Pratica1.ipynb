{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u00cdndices invertidos e busca booleana\n",
      "===================================\n",
      "\n",
      "_Fl\u00e1vio Code\u00e7o Coelho (Com a contribui\u00e7\u00e3o dos alunos do curso de Sistemas de recupera\u00e7\u00e3o de Informa\u00e7\u00f5es da EMAp)_\n",
      "\n",
      "Nesta pr\u00e1tica, vamos contruir um indice invertido e uma m\u00e1quina de busca booleana simples.\n",
      "\n",
      "Para agilizar nosso trabalho, vamos utilizar a biblioteca [NLTK](http://nltk.org) para processamento de linguagem natural."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Em seguida vamos importar mais coisas necess\u00e1rias para o nosso trabalho. Note que estamos baixando a obra completa de Machado de Assis, com a qual iremos alimentar nosso \u00edndice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import machado\n",
      "from nltk.tokenize import WordPunctTokenizer\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "from collections import defaultdict\n",
      "from nltk.stem.snowball import PortugueseStemmer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos tamb\u00e9m baixar o banco de *stopwords* do NLTK. Stop words s\u00e3o um conjunto de palavras que normalmente carregam baixo conte\u00fado sem\u00e2ntico e portanto n\u00e3o s\u00e3o alvo de buscas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.download('stopwords')\n",
      "nltk.download('machado')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package 'stopwords' to\n",
        "[nltk_data]     /home/fccoelho/nltk_data...\n",
        "[nltk_data]   Package stopwords is already up-to-date!\n",
        "[nltk_data] Downloading package 'machado' to\n",
        "[nltk_data]     /home/fccoelho/nltk_data...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lendo o texto *puro* dos livros de Machado:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textos = [machado.raw(id) for id in machado.fileids()]\n",
      "len(textos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "246"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Carregando a  lista de stopwords em lingua portuguesa para limpeza dos textos. Note que \u00e9 preciso trazer as palavras para *UTF-8* antes de us\u00e1-las."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sw = stopwords.words('portuguese') + list (string.punctuation)\n",
      "swu = [word.decode('utf8') for word in sw]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Um outro ingrediente essencial \u00e9 um stemmer para a nossa l\u00edngua. O Stemmer reduz as palavras a uma abrevia\u00e7\u00e3o que se aproxima da \"raiz\" da palavra."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmer = PortugueseStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Preparando o Texto\n",
      "------------------\n",
      "\n",
      "Na c\u00e9lula abaixo, vamos normalizar os nossos textos trazendo todas as palavras para caixa baixa e abreviando-as de forma a deixar apenas as suas ra\u00edzes. Neste passo, removeremos tamb\u00e9m as *stopwords*. Tenha paci\u00eancia, esta an\u00e1lise vai levar algum tempo..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textos_limpos = []\n",
      "for texto in textos:\n",
      "    tlimpo = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
      "    textos_limpos.append(tlimpo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vejamos uma amostra do resultado:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textos_limpos[0][150:160]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[u'uma',\n",
        " u'tal',\n",
        " u'miss',\n",
        " u'doll',\n",
        " u'dev',\n",
        " u'ter',\n",
        " u'poet',\n",
        " u'tennyson',\n",
        " u'cor',\n",
        " u'ler']"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Construindo um \u00cdndice Invertido\n",
      "-------------------------------\n",
      "\n",
      "De posse da nossa lista de termos *normalizados*, podemos agora construir o nosso \u00edndice invertido."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indice = defaultdict(lambda:set([]))\n",
      "for tid,t in enumerate(textos_limpos):\n",
      "    for term in t:\n",
      "        indice[term].add(tid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Podemos verificar a estrutura interna do nosso \u00edndice, procurando por uma palavra:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indice[stemmer.stem(u\"Sal\u00e1rio\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "{3, 51, 77, 165, 182, 192, 193, 219, 220, 222, 232}"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamo ver o contexto em que a palavra *Sal\u00e1rio* ocorre em um dos textos"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.Text(textos[193].encode('utf8').split()).concordance(\"Sal\u00e1rio\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building index...\n",
        "Displaying 2 of 2 matches:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "etite. Os paredistas queriam maior sal\u00e1rio e buscavam o pior caminho. H\u00e1 mei\n",
        " trabalhadeiras levam os saldos do sal\u00e1rio e os lucros advent\u00edcios, eis a\u00ed \n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def busca(consulta):\n",
      "    \"\"\"\n",
      "    A constru\u00e7\u00e3o de uma fun\u00e7\u00e3o de busca \u00e9 deixada com exerc\u00edcio ao leitor\n",
      "    \"\"\"\n",
      "    pass\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mas j\u00e1 podemos utilizar nosso \u00edndice diretamente com alguns termos e verificar como o mesmo \u00e9 eficiente. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time\n",
      "results = indice[stemmer.stem('nacional')]&indice[stemmer.stem('perdi')] - indice[stemmer.stem('campo')]\n",
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3 \u00b5s, sys: 1 \u00b5s, total: 4 \u00b5s\n",
        "Wall time: 8.11 \u00b5s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "{27,\n",
        " 49,\n",
        " 61,\n",
        " 69,\n",
        " 73,\n",
        " 84,\n",
        " 87,\n",
        " 95,\n",
        " 122,\n",
        " 137,\n",
        " 138,\n",
        " 141,\n",
        " 144,\n",
        " 154,\n",
        " 155,\n",
        " 164,\n",
        " 171,\n",
        " 189,\n",
        " 219,\n",
        " 235}"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para um exame mais preciso do tempo de execu\u00e7\u00e3o da nossa consulta, podemos usar a m\u00e1gica do *%%timeit*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "results = indice[stemmer.stem('nacional')]&indice[stemmer.stem('perdi')] - indice[stemmer.stem('campo')]\n",
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 70.7 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}